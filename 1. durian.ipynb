{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitpytorchgpuconda1695c8c3f81347399b40395c973c9be2",
   "display_name": "Python 3.8.5 64-bit ('pytorch-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Build an image classifier that tells if a fruit is a Durian or a Jackfruit\n",
    "---\n",
    "### Key Concepts:\n",
    "  * Image Classifier (2 classes: {Durian, Jackfruit})\n",
    "  * Transfer Learning (ResNet18)\n",
    "  * Pytorch\n",
    "  * ** <u>Local compute and local data</u> **\n",
    "\n",
    "### Learning Objectives:\n",
    "  * Load and explore Image dataset\n",
    "  * Train model\n",
    "  * Predict based on model (Inference) \n",
    "\n",
    "###  Dataset:\n",
    "  * small dataset containing images of Durians and Jackfruits\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "num_channels = 3        # RGB images = 3 channels\n",
    "num_epochs = 2          # Number of Epochs to run the model through\n",
    "learning_rate = 0.001   # Learning rate for the training\n",
    "step_size=7             # Adjust learning rate schedule\n",
    "gamma=0.1               #   step size details how many epochs before decaying LR by gamma \n",
    "\n",
    "data_dir = 'data'       # local folder where the images are stored\n",
    "model_save_path = 'durian.pt' # local folder of the saved model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "source": [
    "## Load and Explore Data\n",
    "---\n",
    "1. Load Durian and Jackfruit images in local folder into train, validate and test datasets using Pytorch DataLoder's\n",
    "1. Explore loaded data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([256, 256]),        \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.ToTensor(),\n",
    "    ])   \n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                        data_transforms[x])\n",
    "                for x in ['train', 'val','test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                            shuffle=True, num_workers=4)\n",
    "            for x in ['train', 'val','test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "print('Classes loaded:',class_names)\n",
    "\n",
    "num_letters = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "# pull some samples from the validation dataset\n",
    "images, labels = next(iter(dataloaders['val']))\n",
    "\n",
    "n_images = len(labels)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % class_names[labels[j]] for j in range(n_images))) \n"
   ]
  },
  {
   "source": [
    "## Train Classifier\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Save the model to a local file\n",
    "    torch.save(model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Started training')\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "print('Number of classes:',len(class_names))\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=gamma)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "print('Model trained.')"
   ]
  },
  {
   "source": [
    "## Inference\n",
    "---\n",
    "1. Test a batch of images\n",
    "1. Test a single image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_names = ['Durian', 'Jackfruit']\n",
    "\n",
    "model = torch.load(model_save_path)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        imshow(torchvision.utils.make_grid(inputs))\n",
    "    \n",
    "        print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]] for j in range(len(labels))))\n",
    "        print('Predicted   : ', ' '.join('%5s' % class_names[preds[j]] for j in range(len(preds))))        \n",
    "        \n",
    "print('')\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(Image.open('data/test/Durian/images (2).jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "    \n",
    "def preprocess(image_file):\n",
    "    \"\"\"Preprocess the input image.\"\"\"\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_file)\n",
    "    image = data_transforms(image).float()\n",
    "    image = torch.tensor(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "input_data = preprocess('data/test/Durian/images (2).jpg')\n",
    "\n",
    "class_names = ['Durian', 'Jackfruit']\n",
    "\n",
    "model = torch.load(model_save_path)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_data = input_data.to(device)\n",
    "\n",
    "    output = model(input_data)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    pred_probs = softmax(output.cpu()).numpy()[0]\n",
    "    index = torch.argmax(output, 1)\n",
    "    result = {\"label\": class_names[index], \"probability\": str(pred_probs[index])}\n",
    "\n",
    "print(result)"
   ]
  }
 ]
}